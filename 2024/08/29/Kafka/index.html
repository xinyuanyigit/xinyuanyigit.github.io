<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><meta name="author" content="WANG"><meta name="renderer" content="webkit"><meta name="copyright" content="WANG"><meta name="keywords" content="WANG's Blog"><meta name="description" content=""><meta name="Cache-Control" content="no-cache"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>Kafka · Mr.Wang's Blog</title><link rel="stylesheet" href="/css/style.css?v=2018.7.9"><link rel="stylesheet" href="/css/animation.css?v=2018.7.9"><link rel="icon" href="/img/assets/favicon.ico"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.6"><!-- scripts--><script>(function( w ){
  "use strict";
  // rel=preload support test
  if( !w.loadCSS ){
    w.loadCSS = function(){};
  }
  // define on the loadCSS obj
  var rp = loadCSS.relpreload = {};
  // rel=preload feature support test
  // runs once and returns a function for compat purposes
  rp.support = (function(){
    var ret;
    try {
      ret = w.document.createElement( "link" ).relList.supports( "preload" );
    } catch (e) {
      ret = false;
    }
    return function(){
      return ret;
    };
  })();

  // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
  // then change that media back to its intended value on load
  rp.bindMediaToggle = function( link ){
    // remember existing media attr for ultimate state, or default to 'all'
    var finalMedia = link.media || "all";

    function enableStylesheet(){
      link.media = finalMedia;
    }

    // bind load handlers to enable media
    if( link.addEventListener ){
      link.addEventListener( "load", enableStylesheet );
    } else if( link.attachEvent ){
      link.attachEvent( "onload", enableStylesheet );
    }

    // Set rel and non-applicable media type to start an async request
    // note: timeout allows this to happen async to let rendering continue in IE
    setTimeout(function(){
      link.rel = "stylesheet";
      link.media = "only x";
    });
    // also enable media after 3 seconds,
    // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
    setTimeout( enableStylesheet, 3000 );
  };

  // loop through link elements in DOM
  rp.poly = function(){
    // double check this to prevent external calls from running
    if( rp.support() ){
      return;
    }
    var links = w.document.getElementsByTagName( "link" );
    for( var i = 0; i < links.length; i++ ){
      var link = links[ i ];
      // qualify links to those with rel=preload and as=style attrs
      if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
        // prevent rerunning on link
        link.setAttribute( "data-loadcss", true );
        // bind listeners to toggle media back
        rp.bindMediaToggle( link );
      }
    }
  };

  // if unsupported, run the polyfill
  if( !rp.support() ){
    // run once at least
    rp.poly();

    // rerun poly on an interval until onload
    var run = w.setInterval( rp.poly, 500 );
    if( w.addEventListener ){
      w.addEventListener( "load", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    } else if( w.attachEvent ){
      w.attachEvent( "onload", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    }
  }


  // commonjs
  if( typeof exports !== "undefined" ){
    exports.loadCSS = loadCSS;
  }
  else {
    w.loadCSS = loadCSS;
  }
}( typeof global !== "undefined" ? global : this ) );</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" defer></script><script src="/js/main.js?v=2018.7.9" defer></script><!-- fancybox--><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script><!-- busuanzi--><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="WANG's Blog" type="application/atom+xml">
</head><body><section class="profile-close" id="cxo-profile"><div class="profile-avatar"><i class="fa fa-caret-left"></i><img src="/img/assets/headerBg.png"></div><!--.profile-saying
  i.fa.fa-comment
  .saying--><div class="cxo-profile-inner"><div class="profile-name">wangkehua</div><div class="profile-signature">for me</div><div class="friends"><div>FRIENDS</div><span><a href="//github.com/Longlongyu" target="_black">friendA</a></span><span><a href="//github.com/" target="_black">friendB</a></span><span><a href="//github.com/" target="_black">friendC</a></span></div><div class="read-progress"></div></div></section><header id="cxo-intro" style="height: 70vh;background-image: url(/img/intro/index-bg.png);"><nav id="cxo-intro-nav"><section><div class="intro-nav-title"><a href="/">Mr.Wang's Blog</a></div><div class="intro-nav-label-box"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div><i class="fa fa-bars intro-nav-menu"><div class="intro-nav-drop"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div></i><div class="clear"></div></section></nav><h1 class="post-title">Kafka</h1><div class="post-intros"><div class="post-intro-meta"><span class="post-intro-time"><i class="post-intro-calendar fa fa-calendar"></i><span>2024-08-29</span></span></div></div></header><article class="cxo-up" id="cxo-content-outer"><section id="cxo-content-inner"><article class="article-entry" id="post"><h2 id="Kafka基础："><a href="#Kafka基础：" class="headerlink" title="Kafka基础："></a>Kafka基础：</h2><h3 id="Kafka是什么？"><a href="#Kafka是什么？" class="headerlink" title="Kafka是什么？"></a>Kafka是什么？</h3><p>Kafka 是一个分布式流式处理平台。</p>
<p>流平台具有三个关键功能：</p>
<p><strong>消息队列</strong>：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。</p>
<p><strong>容错的持久化方式存储记录消息流</strong>：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。</p>
<p><strong>流式处理平台：</strong> 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。</p>
<p><strong>应用场景：</strong></p>
<ol>
<li><strong>消息队列</strong>：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li>
<li><strong>数据处理：</strong> 构建实时的流数据处理程序来转换或处理数据流</li>
</ol>
<h3 id="和其他的消息队列相比，Kafka的优势在哪？"><a href="#和其他的消息队列相比，Kafka的优势在哪？" class="headerlink" title="和其他的消息队列相比，Kafka的优势在哪？"></a>和其他的消息队列相比，Kafka的优势在哪？</h3><p><strong>极致的性能</strong>：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。</p>
<p><strong>生态系统兼容性强</strong>：Kafka 与周边生态系统的兼容性是最好的，尤其在大数据和流计算领域。</p>
<h3 id="队列模型？Kafka的消息模型是什么？"><a href="#队列模型？Kafka的消息模型是什么？" class="headerlink" title="队列模型？Kafka的消息模型是什么？"></a>队列模型？Kafka的消息模型是什么？</h3><p><strong>队列模型：早期的消息模型</strong></p>
<p><img src="/../images/image-20240901112441066.png" alt="image-20240901112441066"></p>
<p><strong>使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。</strong>比如：我们生产者发送 100 条消息的话，两个消费者来消费，一般情况下两个消费者会按照消息发送的顺序各自消费一半。</p>
<p><strong>队列模型存在的问题：</strong></p>
<ol>
<li>消息丢失：在消息传递过程中可能会出现消息丢失的情况，这可能是由于网络故障、系统崩溃等原因导致的。</li>
<li>消息重复：在某些情况下，同一个消息可能会被发送多次，从而导致重复处理。</li>
<li>不能得到完整的消息内容。</li>
</ol>
<p><strong>发布-订阅模型:Kafka 消息模型：</strong></p>
<p>发布-订阅模型主要是为了解决队列模型存在的问题。</p>
<p><img src="/../images/image-20240901112540790.png" alt="image-20240901112540790"></p>
<p>发布订阅模型（Pub-Sub） 使用<strong>主题（Topic）</strong> 作为消息通信载体，类似于<strong>广播模式</strong>；发布者发布一条消息，该消息通过主题传递给所有的订阅者，<strong>在一条消息广播之后才订阅的用户则是收不到该条消息的</strong>。</p>
<p>举个例子来说明这个问题：</p>
<p>假设有一个名为”news”的主题，现在有三个订阅者A、B和C。在这个场景中：</p>
<ol>
<li>发布者向”news”主题发布了第一条新闻消息。</li>
<li>此时，订阅者A和B已经订阅了”news”主题，他们都会收到这条新闻消息。</li>
<li>过了一会儿，订阅者C也开始订阅”news”主题。</li>
<li>但是，由于第一条新闻消息已经在之前就被发布并且传播给了订阅者A和B，所以订阅者C在订阅”news”主题后并不会收到第一条新闻消息。</li>
</ol>
<p><strong>在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。</strong></p>
<p><strong>Kafka 采用的就是发布 - 订阅模型。</strong></p>
<p><strong>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。</strong></p>
<h3 id="Kafka体系架构："><a href="#Kafka体系架构：" class="headerlink" title="Kafka体系架构："></a>Kafka体系架构：</h3><p><img src="/../images/eg1y1l18ts.png" alt="img"></p>
<p>Kafka 依靠 Zookeeper 做分布式协调服务，负责存储和管理 Kafka 集群中的元数据信息，包括集群中的 broker 信息、topic 信息、topic 的分区与副本信息等。</p>
<h3 id="Kafka-术语："><a href="#Kafka-术语：" class="headerlink" title="Kafka 术语："></a>Kafka 术语：</h3><ul>
<li>Producer：生产者，消息产生和发送端。</li>
<li>Broker：Kafka 实例，多个 broker 组成一个 Kafka 集群，通常一台机器部署一个 Kafka 实例，一个实例挂了不影响其他实例。</li>
<li>Consumer：消费者，拉取消息进行消费。 一个 topic 可以让若干个消费者进行消费，若干个消费者组成一个 Consumer Group 即消费组，一条消息只能被消费组中一个 Consumer 消费。</li>
<li>Topic：主题，服务端消息的逻辑存储单元。一个 topic 通常包含若干个 Partition 分区。</li>
<li>Partition：topic 的分区，分布式存储在各个 broker 中， 实现发布与订阅的负载均衡。若干个分区可以被若干个 Consumer 同时消费，达到消费者高吞吐量。一个分区拥有多个副本（Replica），这是Kafka在可靠性和可用性方面的设计。</li>
<li>message：消息，或称日志消息，是 Kafka 服务端实际存储的数据，每一条消息都由一个 key、一个 value 以及消息时间戳 timestamp 组成。</li>
<li>offset：偏移量，分区中的消息位置，由 Kafka 自身维护，Consumer 消费时也要保存一份 offset 以维护消费过的消息位置。</li>
</ul>
<h3 id="Kafka-特点："><a href="#Kafka-特点：" class="headerlink" title="Kafka 特点："></a>Kafka 特点：</h3><ul>
<li><strong>高吞吐量、低延迟</strong>：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒</li>
<li><strong>可扩展性</strong>：kafka集群支持热扩展</li>
<li><strong>持久性、可靠性</strong>：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li><strong>容错性</strong>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li><strong>高并发</strong>：支持数千个客户端同时读写</li>
</ul>
<h2 id="Kafka的核心概念："><a href="#Kafka的核心概念：" class="headerlink" title="Kafka的核心概念："></a>Kafka的核心概念：</h2><h3 id="什么是-Producer、Consumer、Broker、Topic、Partition？"><a href="#什么是-Producer、Consumer、Broker、Topic、Partition？" class="headerlink" title="什么是 Producer、Consumer、Broker、Topic、Partition？"></a>什么是 Producer、Consumer、Broker、Topic、Partition？</h3><p>Kafka 将生产者发布的消息发送到 <strong>Topic（主题）</strong> 中，需要这些消息的消费者可以订阅这些 <strong>Topic（主题）</strong>，</p>
<p><img src="/../images/image-20240901112708118.png" alt="image-20240901112708118"></p>
<p>Kafka 比较重要的几个概念：</p>
<ol>
<li><strong>Producer（生产者）</strong> : 产生消息的一方。</li>
<li><strong>Consumer（消费者）</strong> : 消费消息的一方。</li>
<li><strong>Broker（代理）</strong> : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。</li>
</ol>
<p>每个 Broker 中又包含了 <strong>Topic 以及 Partition</strong> 这两个重要的概念：</p>
<p><strong>Topic（主题）</strong> : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。</p>
<p><strong>Partition（分区）</strong> : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这就表明一个 Topic 可以横跨多个 Broker 。如上图一样。</p>
<blockquote>
<p><strong>Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。</strong></p>
</blockquote>
<h3 id="Kafka的多副本机制？有什么好处？"><a href="#Kafka的多副本机制？有什么好处？" class="headerlink" title="Kafka的多副本机制？有什么好处？"></a>Kafka的多副本机制？有什么好处？</h3><p>分区（Partition）中的多个副本之间会有一个叫做 leader 主副本，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。</p>
<blockquote>
<p>生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。</p>
</blockquote>
<p><strong>Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？</strong></p>
<ol>
<li>Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。</li>
<li>Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。</li>
</ol>
<h2 id="Zookeeper和Kafka："><a href="#Zookeeper和Kafka：" class="headerlink" title="Zookeeper和Kafka："></a>Zookeeper和Kafka：</h2><h3 id="Zookeeper在Kafka中的作用是什么？"><a href="#Zookeeper在Kafka中的作用是什么？" class="headerlink" title="Zookeeper在Kafka中的作用是什么？"></a>Zookeeper在Kafka中的作用是什么？</h3><p>ZooKeeper 主要为 Kafka 提供元数据的管理的功能。</p>
<p>Zookeeper 主要为 Kafka 做了下面这些事情：</p>
<ol>
<li><strong>Broker 注册</strong>：在 Zookeeper 上会有一个专门<strong>用来进行 Broker 服务器列表记录</strong>的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 <code>/brokers/ids</code> 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去</li>
<li><strong>Topic 注册</strong>：在 Kafka 中，同一个<strong>Topic 的消息会被分成多个分区</strong>并将其分布在多个 Broker 上，<strong>这些分区信息及与 Broker 的对应关系</strong>也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：<code>/brokers/topics/my-topic/Partitions/0</code>、<code>/brokers/topics/my-topic/Partitions/1</code></li>
<li><strong>负载均衡</strong>：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。</li>
<li><strong>消息 消费进度Offset 记录：</strong>在消费者对指定消息分区进行消息消费的过程中，<strong>需要定时地将分区消息的消费进度Offset记录到Zookeeper上</strong>，以便在该消费者进行重启或者其他消费者重新接管该消息分区的消息消费后，能够从之前的进度开始继续进行消息消费。Offset在Zookeeper中由一个专门节点进行记录，其节点路径为:&#x2F;consumers&#x2F;[group_id]&#x2F;offsets&#x2F;[topic]&#x2F;[broker_id-partition_id]，节点内容就是Offset的值。</li>
</ol>
<h2 id="Kafka-消费顺序、消息丢失和重复消费"><a href="#Kafka-消费顺序、消息丢失和重复消费" class="headerlink" title="Kafka 消费顺序、消息丢失和重复消费"></a>Kafka 消费顺序、消息丢失和重复消费</h2><h3 id="Kafka-如何保证消息的消费顺序？"><a href="#Kafka-如何保证消息的消费顺序？" class="headerlink" title="Kafka 如何保证消息的消费顺序？"></a>Kafka 如何保证消息的消费顺序？</h3><p>Kafka 中 Partition(分区)是真正保存消息的地方，发送的消息都被放在了这里。而 Partition(分区) 又存在于 Topic(主题) 这个概念中，并且可以给特定 Topic 指定多个 Partition。</p>
<p>每次添加消息到 Partition(分区) 的时候都会采用尾加法，如上图所示。 <strong>Kafka 只能保证 Partition(分区) 中的消息有序。</strong></p>
<p><img src="/../images/image-20240901115225534.png" alt="image-20240901115225534"></p>
<blockquote>
<p>消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。</p>
</blockquote>
<p>所以，就有一种很简单的保证消息消费顺序的方法：<strong>1 个 Topic 只对应一个 Partition</strong>。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。</p>
<p>Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,value（数据） 4 个参数。<strong>如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。</strong>并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表&#x2F;对象的 id 来作为 key 。</p>
<p>对于如何保证 Kafka 中消息消费的顺序，就有了下面两种方法：</p>
<ul>
<li>1 个 Topic 只对应一个 Partition。</li>
<li>（推荐）发送消息的时候指定 topic和Partition。</li>
</ul>
<h3 id="如何保证消息不丢失？"><a href="#如何保证消息不丢失？" class="headerlink" title="如何保证消息不丢失？"></a>如何保证消息不丢失？</h3><p>消息丢失分为三种情况：</p>
<p><strong>生产者消息丢失、消费者消息丢失、Broker消息丢失</strong></p>
<h4 id="生产者消息丢失"><a href="#生产者消息丢失" class="headerlink" title="生产者消息丢失"></a>生产者消息丢失</h4><p>生产者(Producer) 调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。</p>
<p>所以，我们不能默认在调用<code>send</code>方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。 Kafka 生产者(Producer) 使用 <code>send</code> 方法发送消息实际上是异步的操作，返回值是一个Future对象，我们可以通过调用 <code>get()</code>方法获取调用结果，这样的操作会让它变为了同步操作，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="comment">//创建数据</span></span><br><span class="line">    ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(</span><br><span class="line">            <span class="string">&quot;test&quot;</span>,<span class="string">&quot;key&quot;</span>+i,<span class="string">&quot;value&quot;</span>+i</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过生产者对象把数据发送到kafka</span></span><br><span class="line">    <span class="comment">//异步发送数据</span></span><br><span class="line">    Future&lt;RecordMetadata&gt; future = stringStringKafkaProducer.send(record);</span><br><span class="line">    System.out.println(<span class="string">&quot;数据发送中&quot;</span>);</span><br><span class="line">    <span class="comment">//同步发送数据</span></span><br><span class="line">    future.get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第二，可以采用为其添加回调函数的形式，使用异步方式发送数据，代码如下：</p>
<p>在<code>send()</code>方法中创建一个<code>Callback()</code>匿名类,在匿名内中判断数据是否发送成功。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//异步发送数据</span></span><br><span class="line">Future&lt;RecordMetadata&gt; future = stringStringKafkaProducer.send(record, <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (e == <span class="literal">null</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;数据发送成功&quot;</span> + recordMetadata);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;数据发送失败&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>如果消息发送失败的话，我们检查失败的原因之后重新发送即可！</p>
<p><strong>另外，这里推荐为 Producer 的<code>retries</code>（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了。</strong></p>
<h4 id="消费者消息丢失"><a href="#消费者消息丢失" class="headerlink" title="消费者消息丢失"></a>消费者消息丢失</h4><p>消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。</p>
<p><img src="/../images/image-20240901141046077.png" alt="image-20240901141046077"></p>
<p>当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。</p>
<p><strong>解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。</strong> 但是，细心的朋友一定会发现，这样会带来消息被<strong>重新消费的问题</strong>。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。</p>
<h4 id="Broker消息丢失"><a href="#Broker消息丢失" class="headerlink" title="Broker消息丢失"></a>Broker消息丢失</h4><p> Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。</p>
<p>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。</p>
<p><strong>设置 acks &#x3D; all</strong></p>
<p>解决办法就是我们设置 <strong>acks &#x3D; all</strong>。acks 是 Kafka 生产者(Producer) 很重要的一个参数。</p>
<p>acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 <strong>acks &#x3D; all</strong> 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.</p>
<p><strong>设置 unclean.leader.election.enable &#x3D; false</strong></p>
<p>我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 <strong>unclean.leader.election.enable &#x3D; false</strong> 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。</p>
<p><strong>设置 replication.factor &gt;&#x3D; 3</strong></p>
<p>为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 <strong>replication.factor &gt;&#x3D; 3</strong>。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</p>
<p><strong>设置 min.insync.replicas &gt; 1</strong></p>
<p>一般情况下我们还需要设置 <strong>min.insync.replicas&gt; 1</strong> ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。<strong>min.insync.replicas</strong> 的默认值为 1 ，在实际生产中应尽量避免默认值 1。</p>
<p>为了保证整个 Kafka 服务的高可用性，你需要确保 <strong>replication.factor &gt; min.insync.replicas</strong> 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 <strong>replication.factor &#x3D; min.insync.replicas + 1</strong>。</p>
<h3 id="Kafka-如何保证消息不重复消费？"><a href="#Kafka-如何保证消息不重复消费？" class="headerlink" title="Kafka 如何保证消息不重复消费？"></a>Kafka 如何保证消息不重复消费？</h3><p><strong>kafka 出现消息重复消费的原因：</strong></p>
<ul>
<li>服务端侧已经消费的数据没有成功提交 offset（根本原因），触发了重试机制。</li>
<li>Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li><p>消费消息服务做<strong>幂等校验</strong>，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。</p>
</li>
<li><p>将 <strong><code>enable.auto.commit</code></strong> 参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：<strong>什么时候提交 offset 合适？</strong></p>
<ul>
<li><p>处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样</p>
</li>
<li><p>拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。</p>
</li>
</ul>
</li>
</ul>
<h2 id="Kafka消息重试机制"><a href="#Kafka消息重试机制" class="headerlink" title="Kafka消息重试机制"></a>Kafka消息重试机制</h2><h3 id="消费失败会怎么样？"><a href="#消费失败会怎么样？" class="headerlink" title="消费失败会怎么样？"></a>消费失败会怎么样？</h3><p>在消费过程中，当其中一个消息消费异常时，会不会卡住后续队列消息的消费？这样业务岂不是卡住了？</p>
<p>在默认配置下，当消费异常会进行重试，重试多次后会跳过当前消息，继续进行后续消息的消费，不会一直卡在当前消息。因此，即使某个消息消费异常，Kafka 消费者仍然能够继续消费后续的消息，不会一直卡在当前消息，保证了业务的正常进行。</p>
<h3 id="默认会重试多少次？"><a href="#默认会重试多少次？" class="headerlink" title="默认会重试多少次？"></a>默认会重试多少次？</h3><p>默认配置下，消费异常会进行重试，重试次数是多少, 重试是否有时间间隔？</p>
<p>Kafka 消费者在默认配置下会进行<strong>最多 10 次 的重试</strong>，每次重试的<strong>时间间隔为 0</strong>，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，<strong>则不再进行重试，消息将被视为消费失败</strong>。</p>
<h3 id="如何自定义重试次数以及时间间隔"><a href="#如何自定义重试次数以及时间间隔" class="headerlink" title="如何自定义重试次数以及时间间隔?"></a>如何自定义重试次数以及时间间隔?</h3><p>从上面的代码可以知道，默认错误处理器的重试次数以及时间间隔是由 <code>FixedBackOff</code> 控制的，<code>FixedBackOff</code> 是 <code>DefaultErrorHandler</code> 初始化时默认的。所以自定义重试次数以及时间间隔，只需要在 <code>DefaultErrorHandler</code> 初始化的时候传入自定义的 <code>FixedBackOff</code> 即可。重新实现一个 <code>KafkaListenerContainerFactory</code> ，调用 <code>setCommonErrorHandler</code> 设置新的自定义的错误处理器就可以实现。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> KafkaListenerContainerFactory <span class="title function_">kafkaListenerContainerFactory</span><span class="params">(ConsumerFactory&lt;String, String&gt; consumerFactory)</span> &#123;</span><br><span class="line">    <span class="type">ConcurrentKafkaListenerContainerFactory</span> <span class="variable">factory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ConcurrentKafkaListenerContainerFactory</span>();</span><br><span class="line">    <span class="comment">// 自定义重试时间间隔以及次数</span></span><br><span class="line">    <span class="type">FixedBackOff</span> <span class="variable">fixedBackOff</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FixedBackOff</span>(<span class="number">1000</span>, <span class="number">5</span>);</span><br><span class="line">    factory.setCommonErrorHandler(<span class="keyword">new</span> <span class="title class_">DefaultErrorHandler</span>(fixedBackOff));</span><br><span class="line">    factory.setConsumerFactory(consumerFactory);</span><br><span class="line">    <span class="keyword">return</span> factory;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="如何在重试失败后进行告警"><a href="#如何在重试失败后进行告警" class="headerlink" title="如何在重试失败后进行告警?"></a>如何在重试失败后进行告警?</h3><p>自定义重试失败后逻辑，需要手动实现，以下是一个简单的例子，重写 <code>DefaultErrorHandler</code> 的 <code>handleRemaining</code> 函数，加上自定义的告警等操作。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DelErrorHandler</span> <span class="keyword">extends</span> <span class="title class_">DefaultErrorHandler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">DelErrorHandler</span><span class="params">(FixedBackOff backOff)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(<span class="literal">null</span>,backOff);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleRemaining</span><span class="params">(Exception thrownException, List&lt;ConsumerRecord&lt;?, ?&gt;&gt; records, Consumer&lt;?, ?&gt; consumer, MessageListenerContainer container)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.handleRemaining(thrownException, records, consumer, container);</span><br><span class="line">        log.info(<span class="string">&quot;重试多次失败&quot;</span>);</span><br><span class="line">        <span class="comment">// 自定义操作</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>DefaultErrorHandler</code> 只是默认的一个错误处理器，Spring Kafka 还提供了 <code>CommonErrorHandler</code> 接口。手动实现 <code>CommonErrorHandler</code> 就可以实现更多的自定义操作，有很高的灵活性。例如根据不同的错误类型，实现不同的重试逻辑以及业务逻辑等。</p>
<h3 id="重试失败后的数据如何再次处理"><a href="#重试失败后的数据如何再次处理" class="headerlink" title="重试失败后的数据如何再次处理?"></a>重试失败后的数据如何再次处理?</h3><p>当达到最大重试次数后，数据会直接被跳过，继续向后进行。当代码修复后，如何重新消费这些重试失败的数据呢？</p>
<p><strong>死信队列（Dead Letter Queue，简称 DLQ）</strong> 是消息中间件中的一种特殊队列。它主要用于处理无法被消费者正确处理的消息，通常是因为消息格式错误、处理失败、消费超时等情况导致的消息被”丢弃”或”死亡”的情况。当消息进入队列后，消费者会尝试处理它。如果处理失败，或者超过一定的重试次数仍无法被成功处理，消息可以发送到死信队列中，而不是被永久性地丢弃。在死信队列中，可以进一步分析、处理这些无法正常消费的消息，以便定位问题、修复错误，并采取适当的措施。</p>
<p><code>@RetryableTopic</code> 是 Spring Kafka 中的一个注解,它用于配置某个 Topic 支持消息重试，更推荐使用这个注解来完成重试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 重试 5 次，重试间隔 100 毫秒,最大间隔 1 秒</span></span><br><span class="line"><span class="meta">@RetryableTopic(</span></span><br><span class="line"><span class="meta">        attempts = &quot;5&quot;,</span></span><br><span class="line"><span class="meta">        backoff = @Backoff(delay = 100, maxDelay = 1000)</span></span><br><span class="line"><span class="meta">)</span></span><br><span class="line"><span class="meta">@KafkaListener(topics = &#123;KafkaConst.TEST_TOPIC&#125;, groupId = &quot;apple&quot;)</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">customer</span><span class="params">(String message)</span> &#123;</span><br><span class="line">    log.info(<span class="string">&quot;kafka customer:&#123;&#125;&quot;</span>, message);</span><br><span class="line">    <span class="type">Integer</span> <span class="variable">n</span> <span class="operator">=</span> Integer.parseInt(message);</span><br><span class="line">    <span class="keyword">if</span> (n % <span class="number">5</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当达到最大重试次数后，如果仍然无法成功处理消息，消息会被发送到对应的死信队列中。对于死信队列的处理，既可以用 <code>@DltHandler</code> 处理，也可以使用 <code>@KafkaListener</code> 重新消费。</p>
<h2 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h2><h3 id="数据同步一致性问题"><a href="#数据同步一致性问题" class="headerlink" title="数据同步一致性问题"></a>数据同步一致性问题</h3><p>这里有这样一个场景：一个分区有3个副本，一个Leader和两个Follower。Leader副本作为数据的读写副本，所以生产者的数据都会发送给leader副本，而两个follower副本会周期性地同步leader副本的数据，但是因为网络，资源等因素的制约，同步数据的过程是有一定延迟的，所以3个副本之间的数据可能是不同的。</p>
<p><img src="/../images/image-20240901161640074.png" alt="image-20240901161640074"></p>
<p>此时，假设leader副本因为意外原因宕掉了，那么Kafka为了提高分区可用性，此时会选择2个follower副本中的一个作为Leader对外提供数据服务。此时我们就会发现，对于消费者而言，之前leader副本能访问的数据可以到D，但是重新选择leader副本后，能访问的数据就只能到C了，这样消费者就会认为数据丢失了，也就是所谓的数据不一致了。</p>
<p><img src="/../images/image-20240901161811902.png" alt="image-20240901161811902"></p>
<p>为了提升数据的一致性，Kafka引入了高水位（HW ：High Watermark）机制，Kafka在不同的副本之间维护了一个<strong>水位线的机制</strong>（其实也是一个偏移量的概念），消费者只能读取到水位线以下的的数据。<strong>这就是所谓的木桶理论：木桶中容纳水的高度，只能是水桶中最短的那块木板的高度</strong>。这里将整个分区看成一个木桶，其中的数据看成水，而每一个副本就是木桶上的一块木板，那么这个分区（木桶）可以被消费者消费的数据（容纳的水）其实就是数据最少的那个副本的最后数据位置（木板高度）。</p>
<p>也就是说，消费者一开始在消费Leader的时候，虽然Leader副本中已经有a、b、c、d 4条数据，但是由于高水位线的限制，所以也只能消费到a、b这两条数据。</p>
<p><img src="/../images/image-20240901161933715.png" alt="image-20240901161933715"></p>
<p>这样即使leader挂掉了，但是对于消费者来讲，消费到的数据其实还是一样的，因为它能看到的数据是一样的，也就是说，消费者不会认为数据不一致。</p>
<p>不过，因为follower要求和leader的日志数据严格保持一致，所以就需要根据现在Leader的数据偏移量值对其他的副本进行数据截断（truncate）操作。</p>
<p><img src="/../images/image-20240901162119124.png" alt="image-20240901162119124"></p>
<h3 id="HW在副本之间的传递"><a href="#HW在副本之间的传递" class="headerlink" title="HW在副本之间的传递"></a>HW在副本之间的传递</h3><p>HW高水位线会随着follower的数据同步操作，而不断上涨，也就是说，follower同步的数据越多，那么水位线也就越高，那么消费者能访问的数据也就越多。</p>
<p>首先，初始状态下，Leader和Follower都没有数据，所以和偏移量相关的值都是初始值0，而由于Leader需要管理follower，所以也包含着follower的相关偏移量（LEO）数据。</p>
<p><img src="/../images/image-20240901162256010.png" alt="image-20240901162256010"></p>
<p>生产者向Leader发送两条数据，Leader收到数据后，会更新自身的偏移量信息。</p>
<p><strong>Leader副本偏移量更新：</strong>LEO&#x3D;LEO+2&#x3D;2</p>
<p><img src="/../images/image-20240901162347365.png" alt="image-20240901162347365"></p>
<p>接下来，Follower开始同步Leader的数据，同步数据时，会将自身的LEO值作为参数传递给Leader。此时，Leader会将数据传递给Follower，且同时Leader会根据所有副本的LEO值更新HW。</p>
<p><img src="/../images/image-20240901162529433.png" alt="image-20240901162529433"></p>
<p><strong>Leader副本偏移量更新：</strong>HW &#x3D; Math.max[HW, min(LeaderLEO，F1-LEO，F2-LEO)]</p>
<p><img src="/../images/image-20240901163959069.png" alt="image-20240901163959069"></p>
<p>由于两个Follower的数据拉取速率不一致，所以Follower-1抓取了2条数据，而Follower-2抓取了1条数据。Follower收到数据后，会将数据写入文件，并更新自身的偏移量信息。</p>
<p><strong>Follower-1副本偏移量更新：</strong></p>
<p>LEO&#x3D;LEO+2&#x3D;2</p>
<p>HW &#x3D; Math.min[LeaderHW, LEO]</p>
<p><strong>Follower-2副本偏移量更新</strong>：</p>
<p>LEO&#x3D;LEO+1&#x3D;1</p>
<p>HW &#x3D; Math.min[LeaderHW, LEO]</p>
<p><img src="/../images/image-20240901164231768.png" alt="image-20240901164231768"></p>
<p>接下来Leader收到了生产者的数据C，那么此时会根据相同的方式更新自身的偏移量信息</p>
<p><strong>Leader副本偏移量更新</strong>：LEO&#x3D;LEO+1&#x3D;3</p>
<p><img src="/../images/image-20240901164310530.png" alt="image-20240901164310530"></p>
<p>follower接着向Leader发送Fetch请求，同样会将最新的LEO作为参数传递给Leader。Leader收到请求后，会更新自身的偏移量信息。</p>
<p><strong>Leader副本偏移量更新</strong>：HW &#x3D; Math.max[HW, min(LeaderLEO，F1-LEO，F2-LEO)]</p>
<p><img src="/../images/image-20240901164343245.png" alt="image-20240901164343245"></p>
<p>此时，Leader会将数据发送给Follower，同时也会将HW一起发送。</p>
<p><img src="/../images/image-20240901164359895.png" alt="image-20240901164359895"></p>
<p>Follower收到数据后，会将数据写入文件，并更新自身偏移量信息</p>
<p><strong>Follower-1副本偏移量更新：</strong></p>
<p>LEO&#x3D;LEO+1&#x3D;3</p>
<p>HW &#x3D; Math.min[LeaderHW, LEO]</p>
<p><strong>Follower-2副本偏移量更新：</strong></p>
<p>LEO&#x3D;LEO+1&#x3D;2</p>
<p>HW &#x3D; Math.min[LeaderHW, LEO]</p>
<p><img src="/../images/image-20240901164501185.png" alt="image-20240901164501185"></p>
<p>因为Follower会不断重复Fetch数据的过程，所以前面的操作会不断地重复。最终，follower副本和Leader副本的数据和偏移量是保持一致的。</p>
<p><img src="/../images/image-20240901164516595.png" alt="image-20240901164516595"></p>
<p>上面演示了副本列表ISR中Follower副本和Leader副本之间HW偏移量的变化过程，但特殊情况是例外的。比如当前副本列表ISR中，只剩下了Leader一个副本的场合下，是不需要等待其他副本的，直接推高HW即可。</p>
</article><!-- lincense--><div class="license-wrapper"><p> <span>Author:  </span><a href="http://example.com">WANG</a></p><p> <span>Link:  </span><a href="http://example.com/2024/08/29/Kafka/">http://example.com/2024/08/29/Kafka/</a></p><p> <span>Copyright:  </span><span>All articles in this blog are licensed under <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by-nc-nd/3.0">CC BY-NC-SA 3.0</a> unless stating additionally.</span></p></div><div class="post-paginator"><a class="prevSlogan" href="/2024/08/29/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93/" title="Mysql数据库"><span>< PreviousPost</span><br><span class="prevTitle">Mysql数据库</span></a><a class="nextSlogan" href="/2024/08/29/Java%E5%9F%BA%E7%A1%80/" title="Java基础"><span>NextPost ></span><br><span class="nextTitle">Java基础</span></a><div class="clear"></div></div><div id="comment"></div></section></article><footer id="cxo-footer-outer"><div id="cxo-footer-inner"><p class="footer-container"><span>Site by </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span> | theme </span><a target="_blank" rel="noopener" href="https://github.com/Longlongyu/hexo-theme-Cxo"><span>Cxo</span></a></p><i class="fa fa-user"> </i><span id="busuanzi_value_site_uv"></span><span> | </span><i class="fa fa-eye"> </i><span id="busuanzi_value_site_pv"></span></div></footer><!-- catelog--><div class="toc-wrapper" style="top: 70vh;"><div class="toc-catalog"><i class="fa fa-list"> </i><span>CATALOG</span></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E5%9F%BA%E7%A1%80%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">Kafka基础：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">Kafka是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%92%8C%E5%85%B6%E4%BB%96%E7%9A%84%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9B%B8%E6%AF%94%EF%BC%8CKafka%E7%9A%84%E4%BC%98%E5%8A%BF%E5%9C%A8%E5%93%AA%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">和其他的消息队列相比，Kafka的优势在哪？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%9FKafka%E7%9A%84%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">队列模型？Kafka的消息模型是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%EF%BC%9A"><span class="toc-number">1.4.</span> <span class="toc-text">Kafka体系架构：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E6%9C%AF%E8%AF%AD%EF%BC%9A"><span class="toc-number">1.5.</span> <span class="toc-text">Kafka 术语：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E7%89%B9%E7%82%B9%EF%BC%9A"><span class="toc-number">1.6.</span> <span class="toc-text">Kafka 特点：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">Kafka的核心概念：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-Producer%E3%80%81Consumer%E3%80%81Broker%E3%80%81Topic%E3%80%81Partition%EF%BC%9F"><span class="toc-number">2.1.</span> <span class="toc-text">什么是 Producer、Consumer、Broker、Topic、Partition？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%9A%84%E5%A4%9A%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%EF%BC%9F%E6%9C%89%E4%BB%80%E4%B9%88%E5%A5%BD%E5%A4%84%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">Kafka的多副本机制？有什么好处？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zookeeper%E5%92%8CKafka%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">Zookeeper和Kafka：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Zookeeper%E5%9C%A8Kafka%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">3.1.</span> <span class="toc-text">Zookeeper在Kafka中的作用是什么？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%E3%80%81%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%E5%92%8C%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9"><span class="toc-number">4.</span> <span class="toc-text">Kafka 消费顺序、消息丢失和重复消费</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%EF%BC%9F"><span class="toc-number">4.1.</span> <span class="toc-text">Kafka 如何保证消息的消费顺序？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1%EF%BC%9F"><span class="toc-number">4.2.</span> <span class="toc-text">如何保证消息不丢失？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">4.2.1.</span> <span class="toc-text">生产者消息丢失</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">4.2.2.</span> <span class="toc-text">消费者消息丢失</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Broker%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">4.2.3.</span> <span class="toc-text">Broker消息丢失</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="toc-number">4.3.</span> <span class="toc-text">Kafka 如何保证消息不重复消费？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E6%B6%88%E6%81%AF%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6"><span class="toc-number">5.</span> <span class="toc-text">Kafka消息重试机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E5%A4%B1%E8%B4%A5%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7%EF%BC%9F"><span class="toc-number">5.1.</span> <span class="toc-text">消费失败会怎么样？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E4%BC%9A%E9%87%8D%E8%AF%95%E5%A4%9A%E5%B0%91%E6%AC%A1%EF%BC%9F"><span class="toc-number">5.2.</span> <span class="toc-text">默认会重试多少次？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E9%87%8D%E8%AF%95%E6%AC%A1%E6%95%B0%E4%BB%A5%E5%8F%8A%E6%97%B6%E9%97%B4%E9%97%B4%E9%9A%94"><span class="toc-number">5.3.</span> <span class="toc-text">如何自定义重试次数以及时间间隔?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%9C%A8%E9%87%8D%E8%AF%95%E5%A4%B1%E8%B4%A5%E5%90%8E%E8%BF%9B%E8%A1%8C%E5%91%8A%E8%AD%A6"><span class="toc-number">5.4.</span> <span class="toc-text">如何在重试失败后进行告警?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E8%AF%95%E5%A4%B1%E8%B4%A5%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A6%82%E4%BD%95%E5%86%8D%E6%AC%A1%E5%A4%84%E7%90%86"><span class="toc-number">5.5.</span> <span class="toc-text">重试失败后的数据如何再次处理?</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE"><span class="toc-number">6.</span> <span class="toc-text">存储数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-number">6.1.</span> <span class="toc-text">数据同步一致性问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HW%E5%9C%A8%E5%89%AF%E6%9C%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BC%A0%E9%80%92"><span class="toc-number">6.2.</span> <span class="toc-text">HW在副本之间的传递</span></a></li></ol></li></ol></div><!-- top--><i class="fa fa-arrow-up close" id="go-up" aria-hidden="true"></i></body></html>